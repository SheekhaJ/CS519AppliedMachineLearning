{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using manual feature-map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping extra cols from data ----- size of binTrainDF = (1460, 288) and dataDF = (146, 224)\n",
      "After setting cols in data which are not in train to zero ----- size of binTrainDF = (1460, 288) and dataDF = (146, 288)\n",
      "rmsle: 1.956079917253995\n",
      "bias: 9.300898790239067\n",
      "preds before exponentiation: [(9.817638004635576, 11.678439903447801), (11.24985543923975, 12.692503112461443), (10.110978401688715, 11.914047823644255), (9.02750994371888, 11.938193200374572), (10.382139997210443, 12.043553716032399), (7.798660267821924, 11.608235644774552), (10.308463304342164, 12.103486056755072), (11.214058187605724, 11.824079893607152), (10.5397516370016, 12.066810578196666), (10.425946110667816, 11.76718001130949), (7.685526913117499, 11.82700601127654), (10.755801487553441, 12.007560729337492), (8.052940785856338, 11.344506813345266), (11.363323379083777, 12.066810578196666), (8.59724456380836, 12.154779351142624), (10.037049970172188, 12.058152515453552), (9.981195073840935, 11.813030057420567), (10.52037784460832, 12.052338545588132), (10.303854484604921, 12.103486056755072), (10.5280274204777, 11.876873892875459), (10.789790217545963, 11.884489021402711), (10.607050693568048, 11.957611286231675), (10.4015572562402, 11.80894766169701), (10.336735550046647, 11.626254150277232), (10.011953627897203, 11.571194373094205), (11.000261422597921, 11.904967552746252), (10.07594729804625, 11.401993904262946), (7.448407822804453, 11.198214720130528), (10.765801470707142, 12.491251587763836), (7.692932473507614, 11.976659481202368), (10.064030225240115, 11.385092093460344), (7.7146293944419355, 11.931635799828413), (11.006500982460308, 12.468436909997665), (10.771335237738308, 12.141534124392603), (9.78749139695079, 11.37366339763672), (10.017175232213534, 11.461632170582678), (10.153677065509608, 11.678439903447801), (10.308729662700996, 11.976659481202368), (10.859583956294422, 12.05757263721173), (9.566883726785992, 11.808813773969108), (11.191499536712378, 12.095141084822892), (10.52863713580011, 12.01364014498549), (10.464078605557196, 12.031719258385396), (10.642862680992554, 12.106992367829498), (10.130675270293581, 11.302204433654575), (10.82701331945818, 12.26434155365415), (10.954875689336426, 11.678439903447801), (9.73869637808792, 11.695247021764184), (10.348615275647525, 12.254862809699606), (10.776261591846497, 12.147913731356642), (11.24338345653879, 11.401669829409995), (10.026619539102933, 11.695247021764184), (10.210826714361037, 12.246734627249063), (11.31769331793062, 12.487485104968359), (10.298374207031653, 12.078239274020289), (11.790064689252947, 12.270220465353926), (10.549111725119545, 12.450977688625896), (10.711910695750861, 13.021326833226556), (10.960690240988523, 12.17664898415669), (10.92005456695176, 12.524526376648708), (10.349759829894543, 12.323855681186558), (8.350363191797673, 12.034691028774553), (11.676156971893494, 11.320553572322773), (7.206607707180913, 11.440354772135393), (9.895417360364139, 11.813030057420567), (10.233544006943191, 11.385092093460344), (7.985973481626953, 12.031719258385396), (7.6920580858524925, 12.061046873479915), (11.103407740601321, 11.84939770159144), (9.513285059394748, 11.542484267211773), (11.23276867469568, 12.312682380588432), (11.222941356096207, 12.491172637278908), (9.871366627979654, 11.957611286231675), (11.347612921080987, 12.577636201962656), (9.657863372125425, 11.588960151246226), (10.372190572781422, 11.608235644774552), (10.39792312372413, 12.206072645530174), (7.772022530933932, 11.678439903447801), (10.564095265874741, 11.816726919301892), (10.343956474809413, 11.881034786534624), (10.996530523691622, 12.323411137947407), (10.36906886572332, 12.025749091398891), (10.02604205185036, 11.967180737247824), (10.634743692225578, 12.071969661006694), (10.65299481230152, 11.931635799828413), (10.110409132684074, 11.792449349720545), (10.824570541273797, 12.089538829274222), (10.075287180398831, 11.685684782260491), (11.292954563948204, 11.84939770159144), (10.324897799566216, 11.870271183889114), (10.61657031395577, 12.100712129872347), (10.614362379172453, 12.449018824140563), (9.927910779955385, 11.782952602183288), (10.589800852041414, 12.066810578196666), (10.825909445511064, 12.441144767709657), (10.571298659573468, 11.665646551987892), (11.030981532786221, 12.384218830913648), (11.153139853527861, 11.84939770159144), (9.969073953393423, 11.608235644774552), (10.341828950414929, 11.842229212112828), (10.505015651509527, 12.190959007720126), (10.083648990088676, 11.708492248514204), (11.826805418360369, 12.388394202324129), (8.057843001201414, 11.532728092266408), (10.422394508476096, 11.48246625748552), (11.23938645324891, 12.061046873479915), (10.097947673635346, 12.185869938212655), (9.819072567834997, 11.349229372299439), (10.932061803196717, 12.100712129872347), (9.64573539327982, 11.424094251263613), (10.794459119732524, 12.165250651009918), (9.868854731140962, 11.332601910838946), (7.695611565375525, 11.809319478024031), (9.825001328802214, 11.669929213779893), (11.018093959964933, 12.26857785088157), (11.383177519425303, 11.678439903447801), (9.882606893067958, 11.652687407345388), (9.901183943441872, 11.813030057420567), (10.78232057898669, 12.037653993905211), (12.28065023422262, 12.959538518762063), (11.458010730594733, 11.870599909242044), (10.370225066083938, 12.175613438045465), (12.48650953296826, 13.345506928718539), (10.566920732510638, 12.089538829274222), (10.554459197563851, 12.122691036591123), (9.35942174770724, 11.53076538309856), (11.728776537033777, 12.422505731952896), (9.94781183791891, 12.345834587905333), (10.04465454720684, 12.053795210084596), (9.87282408342313, 11.77528972943772), (7.766549758647222, 11.992260421644849), (8.467554249630473, 12.103486056755072), (10.511684833270312, 12.375815420117268), (10.218512800669767, 12.000891794590137), (11.001974142049578, 11.944707881395766), (11.51504886190122, 12.691580461311874), (10.410713164135345, 12.218495165528731), (11.226456710901482, 11.898187865760873), (10.445270728173355, 11.951180395901384), (11.84376652921999, 12.66032791780777), (7.744489532777397, 11.835008964139341), (11.12765803368924, 12.2783933071098), (10.433950326533681, 11.824079893607152), (10.739077817155804, 11.877568578558138), (9.982733571755778, 11.686878772093667), (11.243455548598261, 12.388394202324129)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def remapOnFeatureMap2(data, featureMap2):\n",
    "    remapOnFeatureMap2 = []\n",
    "    \n",
    "    for i, row in enumerate(data):\n",
    "        newRow = []\n",
    "        for j, d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                if (j,d) in featureMap2:\n",
    "                    newRow.append(featureMap2[(j,d)])\n",
    "        remapOnFeatureMap2.append(newRow)\n",
    "    \n",
    "    binRemapped2 = np.zeros((len(data), len(featureMap2)), dtype=float)\n",
    "    for i, row in enumerate(remapOnFeatureMap2):\n",
    "        for j, d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                binRemapped2[i][d] = 1\n",
    "            else:\n",
    "                binRemapped2[i][j] = d\n",
    "        binRemapped2[i][-1] = 1\n",
    "    return binRemapped2\n",
    "\n",
    "def removeNA(data):\n",
    "    for i, row in enumerate(data):\n",
    "        for j, d in enumerate(row):\n",
    "            if d=='NA':\n",
    "                data[i][j] = 0\n",
    "    return data\n",
    "\n",
    "def removeNAFromDF(data):\n",
    "    for col in data.columns:\n",
    "        if col not in binTrainDF.columns:\n",
    "            data = data.drop(col, axis = 1)\n",
    "    print('After dropping extra cols from data ----- size of binTrainDF = {} and dataDF = {}'.format(binTrainDF.shape, data.shape))\n",
    "    \n",
    "    for col in binTrainDF.columns:\n",
    "        if col not in data.columns:\n",
    "            data[col] = 0\n",
    "    print('After setting cols in data which are not in train to zero ----- size of binTrainDF = {} and dataDF = {}'.format(binTrainDF.shape, data.shape))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "#         data[col] = data[col].fillna(0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def writePredictions(ids, preds):\n",
    "    final = [str(i)+','+str(p) for i,p in zip(ids, preds)]\n",
    "    with open('submission.csv', 'w') as output:\n",
    "        output.write('Id,SalePrice\\n')\n",
    "        for x in final:\n",
    "            output.write(str(x))\n",
    "            output.write('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainFile, devFile, testFile = 'train.csv', 'my_dev.csv', 'test.csv'\n",
    "    \n",
    "    train = np.array([s.strip().split(',')[1:-1] for s in open(trainFile).readlines()][1:])\n",
    "    dev = np.array([s.strip().split(',')[1:-1] for s in open(devFile).readlines()][1:])\n",
    "    test = np.array([s.strip().split(',')[1:] for s in open(testFile).readlines()][1:])\n",
    "#     print('len of dev {} and len of test {}'.format(len(dev), len(test)))\n",
    "\n",
    "    header = np.array([s.strip().split(',')[1:-1] for s in open(trainFile).readlines()][0])\n",
    "#     print([(h,val) for h, val in enumerate(header)])\n",
    "    \n",
    "    trainIDs = [s.strip().split(',')[0] for s in open(trainFile).readlines()][1:]\n",
    "    devIDs = [s.strip().split(',')[0] for s in open(devFile).readlines()][1:]\n",
    "    testIDs = [s.strip().split(',')[0] for s in open(testFile).readlines()][1:]\n",
    "    \n",
    "#     trainY = map(float, [s.strip().split(',')[-1] for s in open(trainFile).readlines()][1:])\n",
    "    trainY = map(lambda s : np.log(float(s)), [s.strip().split(',')[-1] for s in open(trainFile).readlines()][1:])\n",
    "    trainY = np.array(list(trainY))\n",
    "#     devY = map(float, [s.strip().split(',')[-1] for s in open(devFile).readlines()][1:])\n",
    "    devY = map(lambda s : np.log(float(s)), [s.strip().split(',')[-1] for s in open(devFile).readlines()][1:])\n",
    "    devY = np.array(list(devY))\n",
    "\n",
    "    train = removeNA(train)\n",
    "    dev = removeNA(dev)\n",
    "    \n",
    "    featureMap = defaultdict()\n",
    "    featureRemap = defaultdict()\n",
    "    featureCategories = defaultdict(list)\n",
    "    for i, row in enumerate(train):\n",
    "        for j, d in enumerate(row):\n",
    "            feature = (j,d)\n",
    "            if feature not in featureMap:\n",
    "                featureMap[feature] = len(featureMap)\n",
    "                featureRemap[len(featureMap)-1] = (feature)\n",
    "                featureCategories[j].append(d)\n",
    "            \n",
    "#     featureMap[(79,0)] = len(featureMap)\n",
    "#     featureRemap[len(featureMap)-1] = (79,0)\n",
    "#     featureCategories[79].append(0)\n",
    "    \n",
    "#     print('Len of feature map: {}'.format(len(featureMap)))\n",
    "#     print(featureRemap)\n",
    "#     print(featureMap)\n",
    "#     print([len(x[1]) for x in featureCategories.items()])\n",
    "#     [print('x0: {} x1: {}'.format(x[0], x[1])) for x in featureCategories.items()]\n",
    "    \n",
    "#     binTrain = remapOnFeatureMap2(train, featureMap)\n",
    "#     binDev = remapOnFeatureMap2(dev, featureMap)\n",
    "#     binTest = remapOnFeatureMap2(test, featureMap)\n",
    "    \n",
    "#     model = LinearRegression().fit(X=binTrain, y=trainY)\n",
    "#     coefs = model.coef_\n",
    "#     intercept = model.intercept_\n",
    "#     preds = model.predict(binTest)\n",
    "    \n",
    "#     print('len(coefs): {} coefs: {}'.format(len(coefs), coefs))\n",
    "#     sortedCoefs = np.argsort(coefs)\n",
    "#     print('Sorted most positive coefs: {}'.format([featureRemap[coef] for coef in sortedCoefs][:10]))\n",
    "#     print('Sorted most negative coefs: {}'.format([featureRemap[coef] for coef in sortedCoefs][-10:]))\n",
    "#     print('mse: {}'.format(np.sqrt(mean_squared_error(devY, preds))))\n",
    "#     print('intercept: {}'.format(intercept))\n",
    "    \n",
    "#     preds = [np.exp(s) for s in preds]\n",
    "#     print('rmse: {}'.format(mean_squared_log_error(devY, preds)))\n",
    "#     print('predictions after exponentiation: {}'.format(list(zip(preds,np.exp(devY)))))\n",
    "\n",
    "#     writePredictions(testIDs, preds)\n",
    "\n",
    "    trainDF, devDF, testDF = pd.read_csv(trainFile), pd.read_csv(devFile), pd.read_csv(testFile)\n",
    "    trainYDF, devYDF = list(map(lambda s: np.log(s), trainDF['SalePrice'])), list(map(lambda s : np.log(s), devDF['SalePrice']))\n",
    "    trainDF, devDF, testDF = trainDF.drop(['Id','SalePrice'], axis = 1), devDF.drop(['Id','SalePrice'], axis = 1), testDF.drop(['Id'], axis = 1)\n",
    "    \n",
    "#     print('numeric cols: {}'.format(trainDF.select_dtypes(np.number).columns))\n",
    "#     print('non-numeric cols: {}'.format(trainDF.select_dtypes(exclude=np.number).columns))\n",
    "    \n",
    "#     num = [2,3,18,19,25,33,35,36,37,42,43,45,58,61,65,66,67,69]\n",
    "#     cat = [0,1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,20,21,22,23,24,26,27,28,29,30,31,32,34,38,39,40,41,44,46,47,48,49,50,51,52,53,54,55,56,57,59,60,62,63,64,68,70,71,72,73,74,75,76,77,78]\n",
    "    \n",
    "    binTrainDF = pd.concat([trainDF[trainDF.select_dtypes(np.number).columns].fillna(0), pd.get_dummies(trainDF[trainDF.select_dtypes(exclude=np.number).columns]).fillna(0)], axis=1)\n",
    "    binDevDF = pd.concat([devDF[devDF.select_dtypes(np.number).columns].fillna(0), pd.get_dummies(devDF[devDF.select_dtypes(exclude=np.number).columns]).fillna(0)], axis = 1)\n",
    "#     binTestDF = pd.concat([pd.get_dummies(testDF[testDF.select_dtypes(np.number).columns]), pd.get_dummies(testDF[testDF.select_dtypes(exclude=np.number).columns])], axis = 1)\n",
    "#     print('size of binTrainDF = {} and binDevDF = {}'.format(binTrainDF.shape, binDevDF.shape))\n",
    "#     print(binTestDF.head())\n",
    "    \n",
    "    binDevDF = removeNAFromDF(binDevDF)\n",
    "#     binTestDF = removeNAFromDF(binTestDF)\n",
    "    \n",
    "    smartModel = LinearRegression().fit(X=binTrainDF, y=trainYDF)    \n",
    "#     print('model coefs len: {}'.format(len(smartModel.coef_)))\n",
    "    smartPreds = smartModel.predict(binDevDF)\n",
    "    print('rmsle: {}'.format(np.sqrt(mean_squared_error(devYDF, smartPreds))))\n",
    "    print('bias: {}'.format(smartModel.intercept_))\n",
    "    print('preds before exponentiation: {}'.format(list(zip(smartPreds, devYDF))))\n",
    "#     smartPreds = [np.exp(s) for s in smartPreds]\n",
    "#     devYDF = [np.exp(s) for s in devYDF]\n",
    "#     print('preds after exponentiation: {}'.format(list(zip(np.exp(smartPreds), np.exp(devYDF)))))\n",
    "#     writePredictions(testIDs, smartPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pandas and numpy to create feature-map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (1460, 79)\n",
      "dev shape: (146, 79)\n",
      "Numeric features cols: Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold'],\n",
      "      dtype='object')\n",
      "Other features cols: Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')\n",
      "Shape of binarized dataframe: (1460, 288)\n",
      "Numeric features cols: Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'MiscVal', 'MoSold', 'YrSold'],\n",
      "      dtype='object')\n",
      "Other features cols: Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'Fence', 'MiscFeature', 'SaleType',\n",
      "       'SaleCondition'],\n",
      "      dtype='object')\n",
      "Shape of binarized dataframe: (146, 225)\n",
      "shape of binDev: (1460,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (146,225) and (288,) not aligned: 225 (dim 1) != 288 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-7383b8872510>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape of binDev: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mtargetPred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinDev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetPred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 198\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (146,225) and (288,) not aligned: 225 (dim 1) != 288 (dim 0)"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def getBinarizedData(data):\n",
    "    numFeatures = data.select_dtypes(np.number).fillna(0)\n",
    "    print('Numeric features cols: {}'.format(numFeatures.columns))\n",
    "#     print(len(numFeatures.columns))\n",
    "    \n",
    "    otherFeatures = data.select_dtypes(exclude=np.number).fillna(0)\n",
    "    print('Other features cols: {}'.format(otherFeatures.columns))\n",
    "#     print(len(otherFeatures.columns))\n",
    "    \n",
    "#     Getting unique values of all non-numeric columns with their corresponding counts\n",
    "#     print([(train[col].unique(), train[col].nunique()) for col in otherFeatures.columns])\n",
    "\n",
    "    binData = pd.concat([pd.get_dummies(data[otherFeatures.columns]), data[numFeatures.columns]], axis = 1).fillna(0)\n",
    "    print('Shape of binarized dataframe: {}'.format(binData.shape))\n",
    "#     print(binData.head())\n",
    "\n",
    "    return binData\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    train, dev = pd.read_csv('train.csv'), pd.read_csv('my_dev.csv')\n",
    "    \n",
    "    trainY, devY = train.SalePrice.astype('float64'), dev.SalePrice.astype('float64')\n",
    "    \n",
    "    train = train.drop(['Id', 'SalePrice'], axis = 1)\n",
    "    dev = dev.drop(['Id', 'SalePrice'], axis = 1)\n",
    "    \n",
    "#     print(train.columns)\n",
    "#     print(dev.columns)\n",
    "    \n",
    "    print('train shape: {}'.format(train.shape))\n",
    "    print('dev shape: {}'.format(dev.shape))\n",
    "    \n",
    "    # To display the dtypes of all columns\n",
    "#     print(train.dtypes)\n",
    "    \n",
    "    binTrain = getBinarizedData(train).astype('float64')\n",
    "    binDev = getBinarizedData(dev).astype('float64')\n",
    "#     print(binTrain.dtypes)\n",
    "\n",
    "    for i, col in enumerate(binTrain.columns):\n",
    "        isnotavailable = np.any(np.isnan(binTrain[col]))\n",
    "        if isnotavailable:\n",
    "            print('isnan is true for col {} and values are {}'.format(col, binTrain[col]))\n",
    "#         else:\n",
    "#             print('col - {} nan - {}'.format(col, isnotavailable))\n",
    "#         print('col - {} inf - {}'.format(col, np.any(np.isfinite(binTrain[col]))))\n",
    "#         print('col - {} float - {}'.format(col, np.issubdtype(binTrain[col], float)))\n",
    "#         print('{}: max val in col \"{}\" is {} '.format(i, col, max(binTrain[col])))\n",
    "#         print('{}) are values for {} in valid float64 range? {}'.format(i, col, np.any(list(True if val < np.finfo(np.float).max else False for val in binTrain[col]))))\n",
    "\n",
    "#     for s in trainY:\n",
    "#         print(trainY[np.isnan(s)==False])\n",
    "#     print('max value of trainY: {}'.format(max(trainY)))\n",
    "    \n",
    "    reg = LinearRegression().fit(binTrain, trainY)\n",
    "    print('shape of binDev: {}'.format(trainY.shape))\n",
    "    targetPred = reg.predict(binDev)\n",
    "    print(mean_squared_log_error(devY, targetPred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
