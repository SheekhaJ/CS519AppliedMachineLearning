{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TA's Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality:  92\n",
      "5000\n",
      "[[   0 2089 4828 ... 4465 3516 3975]\n",
      " [   1 2533  811 ... 4306 1931 3793]]\n",
      "k=1    train_err  1.5% (+: 25.2%) dev_err 23.0% (+: 27.6%)\n",
      "k=3    train_err 11.4% (+: 24.1%) dev_err 19.6% (+: 26.2%)\n",
      "k=5    train_err 13.8% (+: 24.2%) dev_err 17.4% (+: 24.6%)\n",
      "k=7    train_err 14.7% (+: 23.9%) dev_err 16.0% (+: 24.0%)\n",
      "k=9    train_err 15.5% (+: 24.2%) dev_err 15.8% (+: 21.8%)\n",
      "k=41   train_err 17.5% (+: 20.8%) dev_err 14.8% (+: 20.0%)\n",
      "k=99   train_err 17.9% (+: 19.5%) dev_err 15.7% (+: 18.9%)\n",
      "k=999  train_err 20.2% (+: 10.5%) dev_err 18.1% (+: 11.1%)\n",
      "k=1999 train_err 25.0% (+:  0.0%) dev_err 23.6% (+:  0.0%)\n",
      "k=2999 train_err 25.0% (+:  0.0%) dev_err 23.6% (+:  0.0%)\n",
      "k=3999 train_err 25.0% (+:  0.0%) dev_err 23.6% (+:  0.0%)\n",
      "k=4999 train_err 25.0% (+:  0.0%) dev_err 23.6% (+:  0.0%)\n",
      "k=9999 train_err 25.0% (+:  0.0%) dev_err 23.6% (+:  0.0%)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    " # float-point division\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def process_data(filename):\n",
    "    X, Y = [], []\n",
    "    for j, line in enumerate(open(filename)):\n",
    "        line = line.strip()\n",
    "        features = line.split(\", \")\n",
    "        feat_vec = np.zeros(dimension)\n",
    "        for i, fv in enumerate(features[:-1]): # last one is target\n",
    "            if i in [0,7]:\n",
    "                feat_vec[feature_map[i, 0]] = float(fv) / 50.  # NB: diff 2 not 1!\n",
    "            elif (i, fv) in feature_map: # ignore unobserved features\n",
    "                feat_vec[feature_map[i, fv]] = 1\n",
    "\n",
    "        X.append(feat_vec)\n",
    "        Y.append(1 if features[-1] == \">50K\" else -1) # fake for testdata\n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "def process_mx_dist(testX, trainX):\n",
    "    mx_dist=[]\n",
    "    for example in testX:\n",
    "        mx_dist.append(np.linalg.norm(example - trainX, axis=1))\n",
    "    return np.argsort(np.array(mx_dist),axis=1)\n",
    "\n",
    "def knn(k, trainY, mx_dist):\n",
    "    return np.sum(trainY[mx_dist[:,:k]],axis=1)\n",
    "\n",
    "def eval(k, test_XY, trainY, mx_dist):\n",
    "    (testX, testY) = test_XY\n",
    "    pred=np.array([1 if x>0 else -1 for x in knn(k, trainY,mx_dist)])\n",
    "    errors = sum(pred != testY)\n",
    "    positives = sum(pred == 1)\n",
    "    return errors * 100. / len(testX) , positives * 100. / len(testX) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    field_value_freqs = defaultdict(lambda : defaultdict(int)) # field_id -> value -> freq\n",
    "    for line in open(\"income.train.txt.5k\"):\n",
    "        line = line.strip()\n",
    "        features = line.split(\", \")[:-1] # exclude target label\n",
    "        for i, fv in enumerate(features):\n",
    "            field_value_freqs[i][0 if i in [0,7] else fv] += 1\n",
    "\n",
    "    feature_map = {}\n",
    "    feature_remap = {}\n",
    "    for i, value_freqs in field_value_freqs.items():\n",
    "        for v in value_freqs:\n",
    "            k = len(feature_map) # bias\n",
    "            feature_map[i, v] = k\n",
    "            feature_remap[k] = i, v\n",
    "\n",
    "    dimension = len(feature_map) # bias\n",
    "    print(\"dimensionality: \", dimension) #, feature_map\n",
    "\n",
    "    train_data = process_data(\"income.train.txt.5k\") \n",
    "    dev_data = process_data(\"income.dev.txt\")\n",
    "    #test_data = process_data(\"income.test.txt\")\n",
    "    \n",
    "    mx_dist_train=process_mx_dist(train_data[0][:5000],train_data[0][:5000])\n",
    "#     mx_dist_dev=process_mx_dist(dev_data[0][:1000],train_data[0][:5000])\n",
    "    print(len(mx_dist_train[1]))\n",
    "    print(mx_dist_train[:2])\n",
    "\n",
    "    kVals = [1,3,5,7,9,41,99,999,1999,2999,3999,4999,9999]\n",
    "    for k in kVals:\n",
    "#     for k in map(int, sys.argv[1:]):     \n",
    "        print(\"k=%-4d\" % k,\n",
    "              'train_err %4.1f%% (+:%5.1f%%)' % eval(k, (train_data[0][:5000], train_data[1][:5000]), train_data[1][:5000],mx_dist_train),\n",
    "              'dev_err %4.1f%% (+:%5.1f%%)' % eval(k, (dev_data[0][:1000], dev_data[1][:1000]), train_data[1][:5000],mx_dist_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 row: defaultdict(<class 'int'>, {0: 2})\n",
      "0\n",
      "i: 1 row: defaultdict(<class 'int'>, {'Private': 4, 'Self-Employed': 30})\n",
      "Private\n",
      "Self-Employed\n",
      "i: 2 row: defaultdict(<class 'int'>, {'Bachelors': 3, 'High School': 6})\n",
      "Bachelors\n",
      "High School\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "a = defaultdict(lambda : defaultdict(int))\n",
    "a[0][0] = 2\n",
    "a[1]['Private'] = 4\n",
    "a[2]['Bachelors'] = 3\n",
    "a[1]['Self-Employed'] = 30\n",
    "a[2]['High School'] = 6\n",
    "\n",
    "for i,row in a.items():\n",
    "    print('i: {} row: {}'.format(i,row))\n",
    "    for v in row:\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Professor's solution (Has a bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-369228746106>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-49-369228746106>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    def knn(k, example, (trainX, trainY)):\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import division # float-point division\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def process_data(filename):\n",
    "    X, Y = [], []\n",
    "    for j, line in enumerate(open(filename)):\n",
    "        line = line.strip()\n",
    "        features = line.split(\", \")\n",
    "        feat_vec = np.zeros(dimension)\n",
    "        for i, fv in enumerate(features[:-1]): # last one is target\n",
    "            if i in [0,7]:\n",
    "                feat_vec[feature_map[i, 0]] = float(fv) / 50  # NB: diff 2 not 1!\n",
    "            elif (i, fv) in feature_map: # ignore unobserved features\n",
    "                feat_vec[feature_map[i, fv]] = 1\n",
    "\n",
    "        X.append(feat_vec)\n",
    "        Y.append(1 if features[-1] == \">50K\" else -1) # fake for testdata\n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def knn(k, example, (trainX, trainY)):\n",
    "    #dists = [(np.linalg.norm(example - vecx), y) for vecx, y in train_data]\n",
    "    neighbors = np.argpartition(np.linalg.norm(example - trainX, axis=1), k)[:k]\n",
    "    #neighbors = np.argsort(np.linalg.norm(example - trainX, axis=1))[:k]\n",
    "    votes = trainY[neighbors] # slicing\n",
    "    return 1 if sum(votes) > 0 else -1\n",
    "    #return Counter(votes).most_common(1)[0][0] # [(1, 6), (-1, 4)] \n",
    "\n",
    "def eval(k, (testX, testY), train):\n",
    "    pred = np.array([knn(k, vecx, train) for vecx in testX])\n",
    "    errors = sum(pred != testY)\n",
    "    positives = sum(pred == 1)\n",
    "    return errors / len(testX) * 100, positives / len(testX) * 100\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    field_value_freqs = defaultdict(lambda : defaultdict(int)) # field_id -> value -> freq\n",
    "    for line in open(\"income.train.txt.5k\"):\n",
    "        line = line.strip()\n",
    "        features = line.split(\", \")[:-1] # exclude target label\n",
    "        for i, fv in enumerate(features):\n",
    "            field_value_freqs[i][0 if i in [0,7] else fv] += 1\n",
    "\n",
    "    feature_map = {}\n",
    "    feature_remap = {}\n",
    "    for i, value_freqs in field_value_freqs.iteritems():\n",
    "        for v in value_freqs:\n",
    "            k = len(feature_map) # bias\n",
    "            feature_map[i, v] = k\n",
    "            feature_remap[k] = i, v\n",
    "\n",
    "    dimension = len(feature_map) # bias\n",
    "    print \"dimensionality: \", dimension #, feature_map\n",
    "\n",
    "    train_data = process_data(\"income.train.txt.5k\") \n",
    "    dev_data = process_data(\"income.dev.txt\")\n",
    "    #test_data = process_data(\"income.test.txt\")\n",
    "\n",
    "    for k in map(int, sys.argv[1:]):\n",
    "        print \"k=%-4d\" % k,\n",
    "        if k > len(train_data):\n",
    "            k = -1 # infinity; N.B. bug in np.argpartition with very large k\n",
    "        print 'train_err %4.1f%% (+:%5.1f%%)' % eval(k, (train_data[0][:5000], train_data[1][:5000]), train_data),\n",
    "        print 'dev_err %4.1f%% (+:%5.1f%%)' % eval(k, (dev_data[0][:1000], dev_data[1][:1000]), train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 1, 2, 3, 4, 5, 6, 7, 0.26], [0.76, 10, 11, 12, 13, 5, 6, 7, 0.8]]\n",
      "------For train data---------\n",
      "[array([0.        , 0.59093147, 0.54332311, ..., 0.27202941, 0.56320511,\n",
      "       0.79246451]), array([0.59093147, 0.        , 0.3       , ..., 0.83761566, 0.08      ,\n",
      "       0.34      ])]\n",
      "k: 1 error rate: 124.2 positive: 108.5\n",
      "k: 3 error rate: 113.6 positive: 79.1\n",
      "k: 5 error rate: 121.2 positive: 89.5\n",
      "k: 7 error rate: 114.4 positive: 66.5\n",
      "k: 9 error rate: 116.7 positive: 73.4\n",
      "k: 31 error rate: 119.4 positive: 54.9\n",
      "k: 32 error rate: 120.2 positive: 56.9\n",
      "k: 33 error rate: 118.5 positive: 53.0\n",
      "k: 34 error rate: 120.1 positive: 55.0\n",
      "k: 35 error rate: 118.8 positive: 52.5\n",
      "k: 40 error rate: 118.1 positive: 43.4\n",
      "k: 99 error rate: 120.9 positive: 46.4\n",
      "k: 999 error rate: 125.1 positive: 0.0\n",
      "k: 5000 error rate: 125.1 positive: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def getData(fileName):\n",
    "    with open(fileName) as trainTxt:\n",
    "        train = trainTxt.readlines()\n",
    "\n",
    "        #Getting all data except the target column\n",
    "        data = list(map(lambda s : s.strip().split(', '), train))\n",
    "    return data\n",
    "\n",
    "def getAllData(fileName):\n",
    "    with open(fileName) as trainTxt:\n",
    "        train = trainTxt.readlines()\n",
    "\n",
    "    #Getting all data except the target column\n",
    "    data = list(map(lambda s : s.strip().split(', '), train))\n",
    "        \n",
    "    sector = [line[1] for line in data]\n",
    "    education = [line[2] for line in data]\n",
    "    marital = [line[3] for line in data]\n",
    "    occ = [line[4] for line in data]\n",
    "    race = [line[5] for line in data]\n",
    "    gender = [line[6] for line in data]\n",
    "    country = [line[8] for line in data]\n",
    "    \n",
    "    age = [x/50 for x in list(map(int,[line[0] for line in data]))]\n",
    "    hours = [x/50 for x in list(map(int,[line[7] for line in data]))]\n",
    "    \n",
    "    return list(zip(age, sector, education, marital, occ, race, gender, country, hours))\n",
    "\n",
    "def getFeatureMapAndEncodedData(trainData):\n",
    "    featureMapping = {}\n",
    "    encodedTrainData = []\n",
    "    \n",
    "    for row in trainData:\n",
    "        newRow = []\n",
    "        for j,x in enumerate(row):\n",
    "            feature = (j,x)\n",
    "            if feature not in featureMapping:\n",
    "                featureMapping[feature] = len(featureMapping)\n",
    "            newRow.append(featureMapping[feature])\n",
    "        encodedTrainData.append(newRow)\n",
    "        \n",
    "    return featureMapping, encodedTrainData\n",
    "\n",
    "def getTranslatedOnFeatureMap(featureMapping, data):\n",
    "    translatedData = []\n",
    "    \n",
    "    for row in data:\n",
    "        newRow = []\n",
    "        for j,x in enumerate(row):\n",
    "            feature = (j,x)\n",
    "            if j not in [0,8]:\n",
    "                if feature in featureMapping:\n",
    "                    newRow.append(featureMapping[feature])\n",
    "            elif j in [0,8]:\n",
    "                newRow.append(x)\n",
    "        translatedData.append(newRow)\n",
    "    return translatedData\n",
    "\n",
    "def getBinarizedData(unbinarizedData, numberOfFeatures):\n",
    "    finalData = np.zeros((len(unbinarizedData), numberOfFeatures))\n",
    "    for c, row in enumerate(unbinarizedData):\n",
    "        for i,x in enumerate(row):\n",
    "            if isinstance(x,int) and i not in [0,8]:\n",
    "                finalData[c][i] = 1\n",
    "            elif isinstance(x,float) and i in [0,8]:\n",
    "                finalData[c][i] = x\n",
    "    return finalData\n",
    "\n",
    "def getPredictions(topKElements, fileName):\n",
    "    actualIncome = getTarget(getData(fileName))\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(len(topKElements)):\n",
    "        predictedLabelsIndex = [actualIncome[j] for j in topKElements[i]]\n",
    "        predictedLabel = Counter(predictedLabelsIndex).most_common(1)[0][0]\n",
    "        predictions.append(predictedLabel)\n",
    "    return predictions\n",
    "\n",
    "def getNormWithoutIndex(train, test, ord=None):\n",
    "    dist = []\n",
    "    for row in test:\n",
    "        dist.append(np.linalg.norm(row - train, ord, axis = 1))\n",
    "    return dist\n",
    "\n",
    "def getErrorRate(predictions, actualTargetFileName):\n",
    "    actuals = getTarget(getData(actualTargetFileName))\n",
    "    error = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if actuals[i] != predictions[i]:\n",
    "            error+=1\n",
    "    return error/10\n",
    "\n",
    "def getPositives(predictions):\n",
    "    return Counter(predictions)['>50K']/10\n",
    "\n",
    "def getErrorRatesAndPositivePercentage(distWithoutIndex, baselineFileName):\n",
    "    kList = [1,3,5,7,9,31,32,33,34,35,40,99,999,9999]\n",
    "    \n",
    "    topKElements = defaultdict(list)\n",
    "    predictions = defaultdict(list)\n",
    "\n",
    "    for k in kList:\n",
    "        if len(distWithoutIndex) < k:\n",
    "            k = len(distWithoutIndex)\n",
    "            topKElements[k] = [np.argpartition(x,k-1, axis=0)[:k-1] for x in [distWithoutIndex[i] for i in range(len(distWithoutIndex))]]\n",
    "        else:\n",
    "            topKElements[k] = [np.argpartition(x,k, axis=0)[:k] for x in [distWithoutIndex[i] for i in range(len(distWithoutIndex))]]\n",
    "        predictions[k] = getPredictions(topKElements[k], baselineFileName)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def getTarget(data):\n",
    "    return [line[-1] for line in data]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    featureMapping, unbinarizedTrainData = getFeatureMapAndEncodedData(getAllData('income.train.txt.5k'))\n",
    "    unbinarizedTrainData = getTranslatedOnFeatureMap(featureMapping, getAllData('income.train.txt.5k'))\n",
    "#     unbinarizedDevData = getTranslatedOnFeatureMap(featureMapping, getAllData('income.dev.txt'))\n",
    "#     unbinarizedTestData = getTranslatedOnFeatureMap(featureMapping, getAllData('income.test.blind'))\n",
    "\n",
    "    print(unbinarizedTrainData[:2])\n",
    "    binarizedTrainData = getBinarizedData(unbinarizedTrainData, 92)\n",
    "#     binarizedDevData = getBinarizedData(unbinarizedDevData, 92)\n",
    "#     binarizedTestData = getBinarizedData(unbinarizedTestData, 92)\n",
    "\n",
    "    print('------For train data---------')\n",
    "    trainDistWithoutIndex = getNormWithoutIndex(binarizedTrainData, binarizedTrainData)\n",
    "    print(trainDistWithoutIndex[:2])\n",
    "    trainPredictions = getErrorRatesAndPositivePercentage(trainDistWithoutIndex, 'income.train.txt.5k')\n",
    "    for k,preds in trainPredictions.items():\n",
    "        print('k: {} error rate: {} positive: {}'.format(k,getErrorRate(preds, 'income.train.txt.5k'), getPositives(preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
