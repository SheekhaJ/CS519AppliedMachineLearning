{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dimensions: 92\n",
      "k: 10 train_err: 12.64% (+: 23.22) dev_err: 16.400000000000002% (+: 21.6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "def remapOnFeatureMap(data):\n",
    "    remapped = []\n",
    "    for i,row in enumerate(data):\n",
    "        newRow = []\n",
    "        for j,d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                if (j,d) in featureMap:\n",
    "                    newRow.append(featureMap[(j,d)])\n",
    "            else:\n",
    "                newRow.append(float(d)/50)\n",
    "        remapped.append(newRow)\n",
    "        \n",
    "    binRemapped = np.zeros((len(data), len(featureMap)))\n",
    "    for i,row in enumerate(remapped):\n",
    "        for j,d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                binRemapped[i][d] = 1\n",
    "            else:\n",
    "                binRemapped[i][j] = d\n",
    "    \n",
    "    return binRemapped\n",
    "\n",
    "def dist(trainData, testData, ord):\n",
    "    dist = []\n",
    "    for row in testData:\n",
    "        dist.append(np.argsort(np.linalg.norm(trainData - row, ord, axis = 1)))\n",
    "    return dist\n",
    "\n",
    "def knn(distances, target, k):\n",
    "    preds = []\n",
    "    for row in distances:\n",
    "        preds.append(Counter([target[i] for i in row[:k]]).most_common()[0][0])\n",
    "    return preds\n",
    "    \n",
    "def err(preds, target):\n",
    "    return sum([1 if preds[i]!=target[i] else 0 for i in range(len(preds))])/len(preds)*100\n",
    "\n",
    "def pos(preds):\n",
    "    return (sum([preds[i]==1 for i in range(len(preds))])/len(preds))*100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train = [s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines()]\n",
    "    dev = [s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines()]\n",
    "#     test = [s.strip().split(',')[:-1] for s in open('income.test.blind').readlines()]\n",
    "\n",
    "    trainY = [1 if s.strip().split(',')[-1].strip()=='>50K' else 0 for s in open('income.train.txt.5k').readlines()]\n",
    "    devY = [1 if s.strip().split(',')[-1].strip()=='>50K' else 0 for s in open('income.dev.txt').readlines()]\n",
    "    \n",
    "    featureMap = defaultdict(int)\n",
    "    for i, val in enumerate(train):\n",
    "        for j, d in enumerate(val):\n",
    "            feature = (j,d)\n",
    "            if j not in [0,7]:\n",
    "                if feature not in featureMap :\n",
    "                    featureMap[feature] = len(featureMap)\n",
    "            else:\n",
    "                featureMap[(j,0)] = 1\n",
    "                \n",
    "    print('number of dimensions: {}'.format(len(featureMap)))\n",
    "    binTrain = remapOnFeatureMap(train)\n",
    "    binDev = remapOnFeatureMap(dev)\n",
    "#     binTest = remapOnFeatureMap(test)\n",
    "    \n",
    "    devDist = dist(binTrain, binDev,1)\n",
    "    trainDist = dist(binTrain, binTrain,1)\n",
    "    \n",
    "    kVals = [1,3,5,7,9,99,999,1999,2999,3999,4999,9999]\n",
    "    for k in kVals:\n",
    "        devPreds = knn(devDist, trainY, k)\n",
    "        trainPreds = knn(trainDist, trainY, k)\n",
    "        print('k: {} train_err: {}% (+: {}) dev_err: {}% (+: {})'.format(k,err(trainPreds, trainY), pos(trainPreds), err(devPreds, devY), pos(devPreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************Centering data to be zero mean and unit variance************************\n",
      "epoch: 1 dev_err: 2.50% (+ 19.50%)\n",
      "epoch: 2 dev_err: 1.40% (+ 19.40%)\n",
      "epoch: 3 dev_err: 0.50% (+ 19.70%)\n",
      "epoch: 4 dev_err: 0.20% (+ 19.40%)\n",
      "epoch: 5 dev_err: 0.00% (+ 19.40%)\n",
      "epoch: 6 dev_err: 0.20% (+ 19.40%)\n",
      "epoch: 7 dev_err: 0.20% (+ 19.40%)\n",
      "epoch: 8 dev_err: 0.40% (+ 19.60%)\n",
      "epoch: 9 dev_err: 0.40% (+ 19.60%)\n",
      "-----------------------------Test Predictions--------------------------------------------------\n",
      "[1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0]\n",
      "Predicted positive % on test is 19.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def remapOnFeatureMap(data):\n",
    "    remapped = []\n",
    "    for i,row in enumerate(data):\n",
    "        newRow = []\n",
    "        for j,d in enumerate(row):\n",
    "            if (j,d) in featureMap:\n",
    "                newRow.append(featureMap[(j,d)])\n",
    "        remapped.append(newRow)\n",
    "        \n",
    "    binRemapped = np.zeros((len(data), len(featureMap)))\n",
    "    for i,row in enumerate(remapped):\n",
    "        for j,d in enumerate(row):\n",
    "            binRemapped[i][d] = 1\n",
    "        # Adding corresponding value 1 for last bias term\n",
    "        binRemapped[i][-1] = 1\n",
    "    \n",
    "    return binRemapped\n",
    "\n",
    "def perceptronTrain(epochs, data, target):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(featureMap)))\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        u = 0\n",
    "        for i,row in enumerate(data):\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                u += 1\n",
    "                w += target[i]*row\n",
    "        epochData[iteration].append(u)\n",
    "        epochData[iteration].append(w)\n",
    "    return epochData\n",
    "\n",
    "def perceptronPredict(w,data):\n",
    "    preds = []\n",
    "    for i, d in enumerate(data):\n",
    "        preds.append(np.sign(np.dot(w,d)))\n",
    "    return preds\n",
    "\n",
    "def avgPerceptronTrain(epochs, data, target):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(featureMap)))\n",
    "    wa = np.zeros((len(featureMap)))\n",
    "    c = 0\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        for i, row in enumerate(data):\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                w += target[i]*row\n",
    "                wa += c*target[i]*row\n",
    "            c += 1\n",
    "        epochData[iteration].append(c*w - wa)\n",
    "    return epochData\n",
    "\n",
    "def err(preds, target):\n",
    "    return (np.sum([1 if preds[i] == 0 or preds[i]!=target[i] else 0 for i in range(len(preds))]))/len(preds)*100\n",
    "\n",
    "def pos(preds):\n",
    "    return np.sum([1 if preds[i]==1 else 0 for i in range(len(preds))])/len(preds)*100\n",
    "\n",
    "def reorderedData():\n",
    "    print('-------------------------------Reordering training data----------------------------------------------')\n",
    "    reorderedTrain = [s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedTrain.extend([s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "    reorderedTrainY = [1 for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedTrainY.extend([-1 for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "    \n",
    "    reorderedDev = [s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedDev.extend([s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "    reorderedDevY = [1 for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedDevY.extend([-1 for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "\n",
    "    reorderedBinTrain = remapOnFeatureMap(reorderedTrain)\n",
    "    reorderedBinDev = remapOnFeatureMap(reorderedDev)\n",
    "    \n",
    "    for epoch in range(1,10):\n",
    "        epochData = perceptronTrain(epoch, reorderedBinTrain, reorderedTrainY)\n",
    "        updates, wTrain = epochData[epoch-1][0], epochData[epoch-1][1]\n",
    "        devPreds = perceptronPredict(wTrain,reorderedBinDev)\n",
    "        print('epoch: {} updates: {} ({:.2f}%) dev_err: {:.2f}% (+: {:.2f}%)'.format(epoch, updates, (updates/len(reorderedBinTrain))*100, err(devPreds, reorderedDevY), pos(devPreds)))\n",
    "        \n",
    "    print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "    for epoch in range(1,10):\n",
    "        epochData =  avgPerceptronTrain(epoch, reorderedBinTrain, reorderedTrainY)\n",
    "        avgWTrain = epochData[epoch-1][0]\n",
    "        if epoch == 4:\n",
    "            w = epochData[epoch-1][0]\n",
    "        avgDevPreds = perceptronPredict(avgWTrain, binDev)\n",
    "        print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, err(avgDevPreds, reorderedDevY), pos(avgDevPreds)))\n",
    "\n",
    "def featureEngineering1():\n",
    "    featureMap2 = defaultdict(int)\n",
    "    for i, val in enumerate(train):\n",
    "        for j, d in enumerate(val):\n",
    "            feature = (j,d)\n",
    "            if j not in [0,7]:\n",
    "                if feature not in featureMap2:\n",
    "                    featureMap2[feature] = len(featureMap2)\n",
    "    featureMap2[(9,1)] = len(featureMap2)\n",
    "    \n",
    "    return featureMap2\n",
    "    \n",
    "def remapOnFeatureMap2(data, featureMap2, zeroMean, unitVariance):\n",
    "    remapOnFeatureMap2 = []\n",
    "    a = [float(d[0]) for d in data]\n",
    "    h = [float(d[7]) for d in data]\n",
    "    \n",
    "    muAge = np.mean(a)\n",
    "    muHours = np.mean(h)\n",
    "    \n",
    "    sdAge = np.std(a)\n",
    "    sdHours = np.std(h)\n",
    "    \n",
    "    minAge, maxAge = min(a), max(a)\n",
    "    minHours, maxHours = min(h), max(h)\n",
    "    \n",
    "    for i, row in enumerate(data):\n",
    "        newRow = []\n",
    "        for j, d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                if (j,d) in featureMap2:\n",
    "                    newRow.append(featureMap2[(j,d)])\n",
    "            else:\n",
    "                if zeroMean == False and unitVariance == False:\n",
    "                    newRow.append(float(d)/50)\n",
    "                elif zeroMean == True and unitVariance == False:\n",
    "                    if j == 0:\n",
    "                        newRow.append(float(d)-muAge)\n",
    "                    elif j == 7:\n",
    "                        newRow.append(float(d)-muHours)\n",
    "                elif zeroMean == True and unitVariance == True:\n",
    "                    if j == 0:\n",
    "#                         newRow.append((float(d)-minAge)/maxAge-minAge)\n",
    "                        newRow.append((float(d)-muAge)/sdAge)\n",
    "                    elif j == 7:\n",
    "#                         newRow.append((float(d)-minHours)/maxHours-minHours)\n",
    "                        newRow.append((float(d)-muHours)/sdHours)\n",
    "        remapOnFeatureMap2.append(newRow)\n",
    "    \n",
    "    binRemapped2 = np.zeros((len(data), len(featureMap2)), dtype=float)\n",
    "    for i, row in enumerate(remapOnFeatureMap2):\n",
    "        for j, d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                binRemapped2[i][d] = 1\n",
    "            else:\n",
    "                binRemapped2[i][j] = d\n",
    "        binRemapped2[i][-1] = 1\n",
    "    return binRemapped2\n",
    "    \n",
    "def perceptronTrainWithFeatureMap(epochs, data, target, fm):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(fm)))\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        u = 0\n",
    "        for i,row in enumerate(data):\n",
    "            row = np.asarray(row)\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                u += 1\n",
    "                w += target[i]*row\n",
    "        epochData[iteration].append(u)\n",
    "        epochData[iteration].append(w)\n",
    "        \n",
    "    return epochData\n",
    "\n",
    "def avgPerceptronTrainWithFeatureMap(epochs, data, target, fm):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(fm)))\n",
    "    wa = np.zeros((len(fm)))\n",
    "    c = 0\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        for i, row in enumerate(data):\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                w += target[i]*row\n",
    "                wa += c*target[i]*row\n",
    "            c += 1\n",
    "        epochData[iteration].append(c*w - wa)\n",
    "    return epochData\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sns.set()\n",
    "    train = [s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines()]\n",
    "#     dev = [s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines()]\n",
    "    dev = [s.strip().split(',')[:-1] for s in open('income.test.predicted').readlines()]\n",
    "    test = [s.strip().split(',') for s in open('income.test.blind').readlines()]\n",
    "\n",
    "    trainY = [1 if s.strip().split(',')[-1].strip()=='>50K' else -1 for s in open('income.train.txt.5k').readlines()]\n",
    "#     devY = [1 if s.strip().split(',')[-1].strip()=='>50K' else -1 for s in open('income.dev.txt').readlines()]\n",
    "    devY = [1 if s.strip().split(',')[-1].strip()=='>50K' else -1 for s in open('income.test.predicted').readlines()]\n",
    "    \n",
    "    featureMap = defaultdict(int)\n",
    "    featureRemap = {}\n",
    "    for i, val in enumerate(train):\n",
    "        for j, d in enumerate(val):\n",
    "            feature = (j,d)\n",
    "            if feature not in featureMap :\n",
    "                featureMap[feature] = len(featureMap)\n",
    "                featureRemap[len(featureMap)-1] = feature\n",
    "    #Adding last dimension for bias (value = 1) to the feature map\n",
    "    featureMap[(9,0)] = len(featureMap)\n",
    "    featureRemap[len(featureMap)-1] = (9,0)\n",
    "                \n",
    "#     print('number of dimensions: {}'.format(len(featureMap)))\n",
    "    binTrain = remapOnFeatureMap(train)\n",
    "    binDev = remapOnFeatureMap(dev)\n",
    "        \n",
    "#     print(featureMap)\n",
    "#     print('---------------------------------')\n",
    "#     print(featureRemap)\n",
    "\n",
    "    epochs = range(1,10)\n",
    "    \n",
    "#     basicVanErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData = perceptronTrain(epoch, binTrain, trainY)\n",
    "#         updates, wTrain = epochData[epoch-1][0], epochData[epoch-1][1]\n",
    "#         devPreds = perceptronPredict(wTrain,binDev)\n",
    "#         basicVanErrRates[epoch] = err(devPreds, devY)\n",
    "#         print('epoch: {} updates: {} ({:.2f}%) dev_err: {:.2f}% (+: {:.2f}%)'.format(epoch, updates, (updates/len(binTrain))*100, basicVanErrRates[epoch], pos(devPreds)))\n",
    "    \n",
    "#     plt.plot(epochs, basicVanErrRates.values())\n",
    "        \n",
    "#     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "#     basicAvgErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData =  avgPerceptronTrain(epoch, binTrain, trainY)\n",
    "#         avgWTrain = epochData[epoch-1][0]\n",
    "#         if epoch == 4:\n",
    "#             w = epochData[epoch-1][0]\n",
    "#         avgDevPreds = perceptronPredict(avgWTrain, binDev)\n",
    "#         basicAvgErrRates[epoch] = err(avgDevPreds, devY)\n",
    "#         print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, basicAvgErrRates[epoch], pos(avgDevPreds)))\n",
    "    \n",
    "#     plt.plot(epochs, basicAvgErrRates.values())\n",
    "#     plt.legend(['Vanilla Perceptron', 'Average Perceptron'])\n",
    "#     plt.show()\n",
    "        \n",
    "    \n",
    "#     print('************************ Experimentations ************************')\n",
    "#     reorderedData()\n",
    "    \n",
    "#     print('************************Using original numerical features************************')\n",
    "#     fm2 = featureEngineering1()\n",
    "#     binNumFeaturesTrainRemapped = remapOnFeatureMap2(train, fm2, False, False)\n",
    "#     binNumFeaturesDevRemapped = remapOnFeatureMap2(dev, fm2, False, False)\n",
    "\n",
    "#     numFeaturesVanErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData = perceptronTrainWithFeatureMap(epoch, binNumFeaturesTrainRemapped, trainY, fm2)\n",
    "#         updates, wTrain = epochData[epoch-1][0], epochData[epoch-1][1]\n",
    "#         devPreds = perceptronPredict(wTrain,binNumFeaturesDevRemapped)\n",
    "#         numFeaturesVanErrRates[epoch] = err(devPreds, devY)\n",
    "#         print('epoch: {} updates: {} ({:.2f}%) dev_err: {:.2f}% (+: {:.2f}%)'.format(epoch, updates, (updates/len(binNumFeaturesTrainRemapped))*100, numFeaturesVanErrRates[epoch], pos(devPreds)))\n",
    "#     plt.plot(epochs, numFeaturesVanErrRates.values())\n",
    "        \n",
    "#     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "#     numFeaturesAvgErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData =  avgPerceptronTrainWithFeatureMap(epoch, binNumFeaturesTrainRemapped, trainY, fm2)\n",
    "#         avgWTrain = epochData[epoch-1][0]\n",
    "#         if epoch == 4:\n",
    "#             w = epochData[epoch-1][0]\n",
    "#         avgDevPreds = perceptronPredict(avgWTrain, binNumFeaturesDevRemapped)\n",
    "#         numFeaturesAvgErrRates[epoch] = err(avgDevPreds, devY)\n",
    "#         print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, numFeaturesAvgErrRates[epoch], pos(avgDevPreds)))\n",
    "#     plt.plot(epochs, numFeaturesAvgErrRates.values())\n",
    "#     plt.legend(['Vanilla Perceptron with numerical features', 'Average Perceptron with numerical features'])\n",
    "#     plt.show()\n",
    "    \n",
    "#     print('----------------------------Most positive and negative features for average perceptron--------------------------------')\n",
    "#     print('Using weight vector from epoch number 4 when dev_err is minimum')\n",
    "#     print('len of w: {}'.format(len(w)))\n",
    "#     sortedWeights = [(x,w[x]) for x in np.argsort(w)]\n",
    "#     print('weights: {}'.format(sortedWeights))\n",
    "#     print('remap: {}'.format(featureRemap))\n",
    "#     print('At epoch={}, five most negative weight: {}'.format(4, [featureRemap[x] for (x,weight) in sortedWeights[:6]]))\n",
    "#     print('At epoch={}, five most positive weight: {}'.format(4, [featureRemap[x] for (x,weight) in sortedWeights[-6:]]))\n",
    "#     print('----------------------------Feature Weight for Bias Dimension --------------------------------')\n",
    "#     print([w[x] for (x,w[x]) in sortedWeights if x==230])\n",
    "    \n",
    "\n",
    "#     print('************************Centering data to be zero mean************************')\n",
    "#     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "#     zeroMeanErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData =  avgPerceptronTrainWithFeatureMap(epoch, remapOnFeatureMap2(train, featureMap, True, False), trainY, featureMap)\n",
    "#         avgWTrain = epochData[epoch-1][0]\n",
    "#         if epoch == 4:\n",
    "#             w = epochData[epoch-1][0]\n",
    "#         avgDevPreds = perceptronPredict(avgWTrain, remapOnFeatureMap2(dev, featureMap, True, False))\n",
    "#         zeroMeanErrRates[epoch] = err(avgDevPreds, devY)\n",
    "#         print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, zeroMeanErrRates[epoch], pos(avgDevPreds)))\n",
    "#     plt.plot(epochs, zeroMeanErrRates.values())\n",
    "\n",
    "    print('************************Centering data to be zero mean and unit variance************************')\n",
    "#     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "    zeroMeanUnitVarErrRates = defaultdict(float)\n",
    "    for epoch in epochs:\n",
    "        epochData =  avgPerceptronTrainWithFeatureMap(epoch, remapOnFeatureMap2(train, featureMap, True, True), trainY, featureMap)\n",
    "        avgWTrain = epochData[epoch-1][0]\n",
    "        if epoch == 5:\n",
    "            w = epochData[epoch-1][0]\n",
    "        avgDevPreds = perceptronPredict(avgWTrain, remapOnFeatureMap2(dev, featureMap, True, True))\n",
    "        zeroMeanUnitVarErrRates[epoch] = err(avgDevPreds, devY)\n",
    "        print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, zeroMeanUnitVarErrRates[epoch], pos(avgDevPreds)))\n",
    "        \n",
    "#     plt.plot(epochs, zeroMeanUnitVarErrRates.values())\n",
    "#     plt.legend(['Average Perceptron with zero mean', 'Average Perceptron with zero mean and unit variance'])\n",
    "#     plt.show()\n",
    "\n",
    "#     print('-----------------------------Ground truth positive percentage--------------------------------------------------')\n",
    "#     print('Ground truth (+ {:.2f}%)'.format(pos(devY)))\n",
    "\n",
    "    print('-----------------------------Test Predictions--------------------------------------------------')\n",
    "    avgTestPreds = perceptronPredict(w, remapOnFeatureMap2(test, featureMap, True, True))\n",
    "    print(avgTestPreds)\n",
    "    print('Predicted positive % on test is {:.2f}%'.format(pos(avgTestPreds)))\n",
    "    \n",
    "# #     print('-----------------------------Writing Test Predictions to \\'income.test.predicted\\' file--------------------------------------------------')\n",
    "#     final = [i + ['>50K'] if j==1.0 else i+['<=50K'] for i,j in zip(test,avgTestPreds) ]\n",
    "#     l = list(map(lambda d : ','.join(d),final))\n",
    "#     with open('income.test.predicted', 'w') as output:\n",
    "#         for x in l:\n",
    "#             output.write(str(x))\n",
    "#             output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------Average Perceptron--------------------------------------------------\n",
      "epoch: 1 dev_err: 1.00% (+ 19.10%)\n",
      "epoch: 2 dev_err: 1.00% (+ 20.10%)\n",
      "epoch: 3 dev_err: 1.00% (+ 20.10%)\n",
      "epoch: 4 dev_err: 1.00% (+ 20.00%)\n",
      "epoch: 5 dev_err: 1.00% (+ 20.40%)\n",
      "epoch: 6 dev_err: 1.00% (+ 20.60%)\n",
      "epoch: 7 dev_err: 1.00% (+ 20.50%)\n",
      "epoch: 8 dev_err: 1.00% (+ 20.90%)\n",
      "epoch: 9 dev_err: 1.00% (+ 21.00%)\n",
      "[4.3]\n",
      "[ 1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1\n",
      " -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "def remapOnFeatureMap(data):\n",
    "    remapped = []\n",
    "    for i,row in enumerate(data):\n",
    "        newRow = []\n",
    "        for j,d in enumerate(row):\n",
    "            if (j,d) in featureMap:\n",
    "                newRow.append(featureMap[(j,d)])\n",
    "        remapped.append(newRow)\n",
    "        \n",
    "    binRemapped = np.zeros((len(data), len(featureMap)))\n",
    "    for i,row in enumerate(remapped):\n",
    "        for j,d in enumerate(row):\n",
    "            binRemapped[i][d] = 1\n",
    "        # Adding corresponding value 1 for last bias term\n",
    "        binRemapped[i][-1] = 1\n",
    "    \n",
    "    return binRemapped\n",
    "\n",
    "def perceptronTrain(epochs, data, target):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(featureMap)))\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        u = 0\n",
    "        for i,row in enumerate(data):\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                u += 1\n",
    "                w += target[i]*row\n",
    "        epochData[iteration].append(u)\n",
    "        epochData[iteration].append(w)\n",
    "    return epochData\n",
    "\n",
    "def perceptronPredict(w,data):\n",
    "    preds = []\n",
    "    for i, d in enumerate(data):\n",
    "        preds.append(np.sign(np.dot(w,d)))\n",
    "    return preds\n",
    "\n",
    "def avgPerceptronTrain(epochs, data, target):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(featureMap)))\n",
    "    wa = np.zeros((len(featureMap)))\n",
    "    c = 0\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        for i, row in enumerate(data):\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                w += target[i]*row\n",
    "                wa += c*target[i]*row\n",
    "            c += 1\n",
    "        epochData[iteration].append(c*w - wa)\n",
    "    return epochData\n",
    "\n",
    "def err(preds, target):\n",
    "    return (np.sum([1 if preds[i] == 0 or preds[i]!=target[i] else 0 for i in range(len(preds))]))/len(preds)*100\n",
    "\n",
    "def pos(preds):\n",
    "    return np.sum([1 if preds[i]==1 else 0 for i in range(len(preds))])/len(preds)*100\n",
    "\n",
    "def reorderedData():\n",
    "    print('-------------------------------Reordering training data----------------------------------------------')\n",
    "    reorderedTrain = [s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedTrain.extend([s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "    reorderedTrainY = [1 for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedTrainY.extend([-1 for s in open('income.train.txt.5k').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "    \n",
    "    reorderedDev = [s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedDev.extend([s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "    reorderedDevY = [1 for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' >50K']\n",
    "    reorderedDevY.extend([-1 for s in open('income.dev.txt').readlines() if s.strip().split(',')[-1]==' <=50K'])\n",
    "\n",
    "    reorderedBinTrain = remapOnFeatureMap(reorderedTrain)\n",
    "    reorderedBinDev = remapOnFeatureMap(reorderedDev)\n",
    "    \n",
    "    for epoch in range(1,10):\n",
    "        epochData = perceptronTrain(epoch, reorderedBinTrain, reorderedTrainY)\n",
    "        updates, wTrain = epochData[epoch-1][0], epochData[epoch-1][1]\n",
    "        devPreds = perceptronPredict(wTrain,reorderedBinDev)\n",
    "        print('epoch: {} updates: {} ({:.2f}%) dev_err: {:.2f}% (+: {:.2f}%)'.format(epoch, updates, (updates/len(reorderedBinTrain))*100, err(devPreds, reorderedDevY), pos(devPreds)))\n",
    "        \n",
    "    print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "    for epoch in range(1,10):\n",
    "        epochData =  avgPerceptronTrain(epoch, reorderedBinTrain, reorderedTrainY)\n",
    "        avgWTrain = epochData[epoch-1][0]\n",
    "        if epoch == 4:\n",
    "            w = epochData[epoch-1][0]\n",
    "        avgDevPreds = perceptronPredict(avgWTrain, binDev)\n",
    "        print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, err(avgDevPreds, reorderedDevY), pos(avgDevPreds)))\n",
    "\n",
    "def featureEngineering1():\n",
    "    featureMap2 = defaultdict(int)\n",
    "    for i, val in enumerate(train):\n",
    "        for j, d in enumerate(val):\n",
    "            feature = (j,d)\n",
    "            if j not in [0,7]:\n",
    "                if feature not in featureMap2:\n",
    "                    featureMap2[feature] = len(featureMap2)\n",
    "    featureMap2[(9,1)] = len(featureMap2)\n",
    "    \n",
    "    return featureMap2\n",
    "    \n",
    "def remapOnFeatureMap2(data, featureMap2, zeroMean, unitVariance):\n",
    "    remapOnFeatureMap2 = []\n",
    "    a = [float(d[0]) for d in data]\n",
    "    h = [float(d[7]) for d in data]\n",
    "    \n",
    "    muAge = np.mean(a)\n",
    "    muHours = np.mean(h)\n",
    "    \n",
    "    sdAge = np.std(a)\n",
    "    sdHours = np.std(h)\n",
    "    \n",
    "    minAge, maxAge = min(a), max(a)\n",
    "    minHours, maxHours = min(h), max(h)\n",
    "    \n",
    "    for i, row in enumerate(data):\n",
    "        newRow = []\n",
    "        for j, d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                if (j,d) in featureMap2:\n",
    "                    newRow.append(featureMap2[(j,d)])\n",
    "            else:\n",
    "                if zeroMean == False and unitVariance == False:\n",
    "                    newRow.append(float(d)/50)\n",
    "                elif zeroMean == True and unitVariance == False:\n",
    "                    if j == 0:\n",
    "                        newRow.append(float(d)-muAge)\n",
    "                    elif j == 7:\n",
    "                        newRow.append(float(d)-muHours)\n",
    "                elif zeroMean == True and unitVariance == True:\n",
    "                    if j == 0:\n",
    "#                         newRow.append((float(d)-minAge)/maxAge-minAge)\n",
    "                        newRow.append((float(d)-muAge)/sdAge)\n",
    "                    elif j == 7:\n",
    "#                         newRow.append((float(d)-minHours)/maxHours-minHours)\n",
    "                        newRow.append((float(d)-muHours)/sdHours)\n",
    "        remapOnFeatureMap2.append(newRow)\n",
    "    \n",
    "    binRemapped2 = np.zeros((len(data), len(featureMap2)), dtype=float)\n",
    "    for i, row in enumerate(remapOnFeatureMap2):\n",
    "        for j, d in enumerate(row):\n",
    "            if j not in [0,7]:\n",
    "                binRemapped2[i][d] = 1\n",
    "            else:\n",
    "                binRemapped2[i][j] = d\n",
    "        binRemapped2[i][-1] = 1\n",
    "    return binRemapped2\n",
    "    \n",
    "def perceptronTrainWithFeatureMap(epochs, data, target, fm):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(fm)))\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        u = 0\n",
    "        for i,row in enumerate(data):\n",
    "            row = np.asarray(row)\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                u += 1\n",
    "                w += target[i]*row\n",
    "        epochData[iteration].append(u)\n",
    "        epochData[iteration].append(w)\n",
    "        \n",
    "    return epochData\n",
    "\n",
    "def avgPerceptronTrainWithFeatureMap(epochs, data, target, fm):\n",
    "    epochData = defaultdict(list)\n",
    "    w = np.zeros((len(fm)))\n",
    "    wa = np.zeros((len(fm)))\n",
    "    c = 0\n",
    "    \n",
    "    for iteration in range(epochs):\n",
    "        for i, row in enumerate(data):\n",
    "            a = np.sum(np.dot(w,row))\n",
    "            if target[i]*a <= 0:\n",
    "                w += target[i]*row\n",
    "                wa += c*target[i]*row\n",
    "            c += 1\n",
    "        epochData[iteration].append(c*w - wa)\n",
    "    return epochData\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sns.set()\n",
    "    train = [s.strip().split(',')[:-1] for s in open('income.train.txt.5k').readlines()]\n",
    "#     dev = [s.strip().split(',')[:-1] for s in open('income.dev.txt').readlines()]\n",
    "#     dev = [s.strip().split(',')[:-1] for s in open('income.test.predicted').readlines()]\n",
    "    test = [s.strip().split(',') for s in open('income.test.blind').readlines()]\n",
    "\n",
    "    trainY = [1 if s.strip().split(',')[-1].strip()=='>50K' else -1 for s in open('income.train.txt.5k').readlines()]\n",
    "#     devY = [1 if s.strip().split(',')[-1].strip()=='>50K' else -1 for s in open('income.dev.txt').readlines()]\n",
    "    devY = [1 if s.strip().split(',')[-1].strip()=='>50K' else -1 for s in open('income.test.predicted').readlines()]\n",
    "    \n",
    "    featureMap = defaultdict(int)\n",
    "    featureRemap = {}\n",
    "    for i, val in enumerate(train):\n",
    "        for j, d in enumerate(val):\n",
    "            feature = (j,d)\n",
    "            if feature not in featureMap :\n",
    "                featureMap[feature] = len(featureMap)\n",
    "                featureRemap[len(featureMap)-1] = feature\n",
    "    #Adding last dimension for bias (value = 1) to the feature map\n",
    "    featureMap[(9,0)] = len(featureMap)\n",
    "    featureRemap[len(featureMap)-1] = (9,0)\n",
    "                \n",
    "#     print('number of dimensions: {}'.format(len(featureMap)))\n",
    "    binTrain = remapOnFeatureMap(train)\n",
    "    binDev = remapOnFeatureMap(dev)\n",
    "    binTest = remapOnFeatureMap(test)\n",
    "        \n",
    "#     print(featureMap)\n",
    "#     print('---------------------------------')\n",
    "#     print(featureRemap)\n",
    "\n",
    "    epochs = range(1,10)\n",
    "    \n",
    "#     basicVanErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData = perceptronTrain(epoch, binTrain, trainY)\n",
    "#         updates, wTrain = epochData[epoch-1][0], epochData[epoch-1][1]\n",
    "#         devPreds = perceptronPredict(wTrain,binDev)\n",
    "#         basicVanErrRates[epoch] = err(devPreds, devY)\n",
    "#         print('epoch: {} updates: {} ({:.2f}%) dev_err: {:.2f}% (+: {:.2f}%)'.format(epoch, updates, (updates/len(binTrain))*100, basicVanErrRates[epoch], pos(devPreds)))\n",
    "    \n",
    "#     plt.plot(epochs, basicVanErrRates.values())\n",
    "        \n",
    "    print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "    basicAvgErrRates = defaultdict(float)\n",
    "    for epoch in epochs:\n",
    "        epochData =  avgPerceptronTrain(epoch, binTrain, trainY)\n",
    "        avgWTrain = epochData[epoch-1][0]\n",
    "        if epoch == 4:\n",
    "            w = epochData[epoch-1][0]\n",
    "        avgDevPreds = perceptronPredict(avgWTrain, binDev)\n",
    "        basicAvgErrRates[epoch] = err(avgDevPreds, devY)\n",
    "        print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, basicAvgErrRates[epoch], pos(avgDevPreds)))\n",
    "    \n",
    "#     plt.plot(epochs, basicAvgErrRates.values())\n",
    "#     plt.legend(['Vanilla Perceptron', 'Average Perceptron'])\n",
    "#     plt.show()\n",
    "        \n",
    "    clf = Perceptron(tol=1e-3, random_state=0)\n",
    "    clf.fit(binTrain, trainY)\n",
    "    a = clf.predict(binTest)\n",
    "    print([pos(a)])\n",
    "    print(a)\n",
    "    \n",
    "#     print('************************ Experimentations ************************')\n",
    "#     reorderedData()\n",
    "    \n",
    "#     print('************************Using original numerical features************************')\n",
    "#     fm2 = featureEngineering1()\n",
    "#     binNumFeaturesTrainRemapped = remapOnFeatureMap2(train, fm2, False, False)\n",
    "#     binNumFeaturesDevRemapped = remapOnFeatureMap2(dev, fm2, False, False)\n",
    "\n",
    "#     numFeaturesVanErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData = perceptronTrainWithFeatureMap(epoch, binNumFeaturesTrainRemapped, trainY, fm2)\n",
    "#         updates, wTrain = epochData[epoch-1][0], epochData[epoch-1][1]\n",
    "#         devPreds = perceptronPredict(wTrain,binNumFeaturesDevRemapped)\n",
    "#         numFeaturesVanErrRates[epoch] = err(devPreds, devY)\n",
    "#         print('epoch: {} updates: {} ({:.2f}%) dev_err: {:.2f}% (+: {:.2f}%)'.format(epoch, updates, (updates/len(binNumFeaturesTrainRemapped))*100, numFeaturesVanErrRates[epoch], pos(devPreds)))\n",
    "#     plt.plot(epochs, numFeaturesVanErrRates.values())\n",
    "        \n",
    "#     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "#     numFeaturesAvgErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData =  avgPerceptronTrainWithFeatureMap(epoch, binNumFeaturesTrainRemapped, trainY, fm2)\n",
    "#         avgWTrain = epochData[epoch-1][0]\n",
    "#         if epoch == 4:\n",
    "#             w = epochData[epoch-1][0]\n",
    "#         avgDevPreds = perceptronPredict(avgWTrain, binNumFeaturesDevRemapped)\n",
    "#         numFeaturesAvgErrRates[epoch] = err(avgDevPreds, devY)\n",
    "#         print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, numFeaturesAvgErrRates[epoch], pos(avgDevPreds)))\n",
    "#     plt.plot(epochs, numFeaturesAvgErrRates.values())\n",
    "#     plt.legend(['Vanilla Perceptron with numerical features', 'Average Perceptron with numerical features'])\n",
    "#     plt.show()\n",
    "    \n",
    "#     print('----------------------------Most positive and negative features for average perceptron--------------------------------')\n",
    "#     print('Using weight vector from epoch number 4 when dev_err is minimum')\n",
    "#     print('len of w: {}'.format(len(w)))\n",
    "#     sortedWeights = [(x,w[x]) for x in np.argsort(w)]\n",
    "#     print('weights: {}'.format(sortedWeights))\n",
    "#     print('remap: {}'.format(featureRemap))\n",
    "#     print('At epoch={}, five most negative weight: {}'.format(4, [featureRemap[x] for (x,weight) in sortedWeights[:6]]))\n",
    "#     print('At epoch={}, five most positive weight: {}'.format(4, [featureRemap[x] for (x,weight) in sortedWeights[-6:]]))\n",
    "#     print('----------------------------Feature Weight for Bias Dimension --------------------------------')\n",
    "#     print([w[x] for (x,w[x]) in sortedWeights if x==230])\n",
    "    \n",
    "\n",
    "#     print('************************Centering data to be zero mean************************')\n",
    "#     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "#     zeroMeanErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData =  avgPerceptronTrainWithFeatureMap(epoch, remapOnFeatureMap2(train, featureMap, True, False), trainY, featureMap)\n",
    "#         avgWTrain = epochData[epoch-1][0]\n",
    "#         if epoch == 4:\n",
    "#             w = epochData[epoch-1][0]\n",
    "#         avgDevPreds = perceptronPredict(avgWTrain, remapOnFeatureMap2(dev, featureMap, True, False))\n",
    "#         zeroMeanErrRates[epoch] = err(avgDevPreds, devY)\n",
    "#         print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, zeroMeanErrRates[epoch], pos(avgDevPreds)))\n",
    "#     plt.plot(epochs, zeroMeanErrRates.values())\n",
    "\n",
    "#     print('************************Centering data to be zero mean and unit variance************************')\n",
    "# #     print('-----------------------------Average Perceptron--------------------------------------------------')\n",
    "#     zeroMeanUnitVarErrRates = defaultdict(float)\n",
    "#     for epoch in epochs:\n",
    "#         epochData =  avgPerceptronTrainWithFeatureMap(epoch, remapOnFeatureMap2(train, featureMap, True, True), trainY, featureMap)\n",
    "#         avgWTrain = epochData[epoch-1][0]\n",
    "#         if epoch == 5:\n",
    "#             w = epochData[epoch-1][0]\n",
    "#         avgDevPreds = perceptronPredict(avgWTrain, remapOnFeatureMap2(dev, featureMap, True, True))\n",
    "#         zeroMeanUnitVarErrRates[epoch] = err(avgDevPreds, devY)\n",
    "#         print('epoch: {} dev_err: {:.2f}% (+ {:.2f}%)'.format(epoch, zeroMeanUnitVarErrRates[epoch], pos(avgDevPreds)))\n",
    "        \n",
    "#     plt.plot(epochs, zeroMeanUnitVarErrRates.values())\n",
    "#     plt.legend(['Average Perceptron with zero mean', 'Average Perceptron with zero mean and unit variance'])\n",
    "#     plt.show()\n",
    "\n",
    "#     print('-----------------------------Ground truth positive percentage--------------------------------------------------')\n",
    "#     print('Ground truth (+ {:.2f}%)'.format(pos(devY)))\n",
    "\n",
    "#     print('-----------------------------Test Predictions--------------------------------------------------')\n",
    "#     avgTestPreds = perceptronPredict(w, remapOnFeatureMap2(test, featureMap, True, True))\n",
    "#     print('Predicted positive % on test is {:.2f}%'.format(pos(avgTestPreds)))\n",
    "    \n",
    "# #     print('-----------------------------Writing Test Predictions to \\'income.test.predicted\\' file--------------------------------------------------')\n",
    "#     final = [i + ['>50K'] if j==1.0 else i+['<=50K'] for i,j in zip(test,avgTestPreds) ]\n",
    "#     l = list(map(lambda d : ','.join(d),final))\n",
    "#     with open('income.test.predicted', 'w') as output:\n",
    "#         for x in l:\n",
    "#             output.write(str(x))\n",
    "#             output.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TA's Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Perceptron and Averaged Perceptron\n",
      "dimensionality:  1042\n",
      "X1: [[ 1.     -0.0016 -0.0166 ...  0.      0.      0.    ]\n",
      " [ 1.     -0.0016 -0.0166 ...  0.      0.      0.    ]\n",
      " [ 1.     -0.0016 -0.0166 ...  0.      0.      0.    ]\n",
      " [ 1.     -0.0016 -0.0166 ...  0.      0.      0.    ]\n",
      " [ 1.     -0.0016 -0.0166 ...  0.      0.      0.    ]]\n",
      "unavg, epoch 1 updates 1182 (23.6%) dev_err 21.2% (+:28.2%);    avg, epoch 1 dev_err 13.7% (+:19.1%)\n",
      "unavg, epoch 2 updates 1121 (22.4%) dev_err 20.8% (+:27.2%);    avg, epoch 2 dev_err 14.9% (+:21.3%)\n",
      "unavg, epoch 3 updates 1097 (21.9%) dev_err 23.1% (+:29.7%);    avg, epoch 3 dev_err 15.1% (+:21.5%)\n",
      "unavg, epoch 4 updates 1095 (21.9%) dev_err 21.5% (+:25.1%);    avg, epoch 4 dev_err 15.5% (+:22.1%)\n",
      "unavg, epoch 5 updates 1066 (21.3%) dev_err 20.7% (+:26.5%);    avg, epoch 5 dev_err 15.4% (+:22.0%)\n",
      "training time 0.44104 s\n",
      "train_err 16.46% (+:20.2%)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from __future__ import division\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def normalization(data_X, mean = False, variance = False, norm_para=None):\n",
    "    data_X = np.array(data_X)\n",
    "    if norm_para is None:    # calc for training data\n",
    "        feat_mean = np.mean(data_X,0)   # mean along 0 axis (vertical)\n",
    "        feat_std  = np.std(data_X,0)\n",
    "        feat_std[feat_std < 1e-10] = 1.0    # in case some features not appear in dev or test data, resulting 0-std in normalization\n",
    "    else:               # use scales from training data\n",
    "        feat_mean, feat_std = norm_para\n",
    "\n",
    "    if mean:\n",
    "        data_X = data_X - feat_mean\n",
    "    if variance:\n",
    "        data_X = data_X / feat_std\n",
    "    data_X[:,0] = 1.0    # resume the bias feature to 1\n",
    "\n",
    "    return data_X, feat_mean, feat_std\n",
    "\n",
    "def map_data(filename, feature2index, mean = False, variance = False, norm_para = None):\n",
    "    data_X = []\n",
    "    data_Y, last = (None, None) if 'blind' in filename else ([], -1)    # last is the position of last valid column\n",
    "    dimension = len(feature2index)\n",
    "    for j1, line in enumerate(open(filename)):\n",
    "        line = line.strip()\n",
    "        features = line.split(\", \")\n",
    "        feat_vec = np.zeros(dimension)\n",
    "        for i, fv in enumerate(features[:last]):    # train/dev: last one is target; test: last is also a col in feature\n",
    "            if (i, fv) in feature2index:            # ignore unobserved features\n",
    "                feat_vec[feature2index[i, fv]] = 1.0\n",
    "\n",
    "        # engineering for feature combination\n",
    "        for i, j in combinations(comb, 2):\n",
    "            if (i, features[i], j, features[j]) in feature2index:     # ignore unobserved combined features\n",
    "                feat_vec[feature2index[i, features[i], j, features[j]]] = 1.0\n",
    "\n",
    "        # engineering for 2 numerical features addition\n",
    "        if numerical: \n",
    "            feat_vec = np.append(feat_vec, [float(features[0]), float(features[7])])  # numerical age, numerical hours  \n",
    "        data_X.append(feat_vec)\n",
    "        if last is not None: \n",
    "            data_Y.append(1 if features[-1] == \">50K\" else -1)\n",
    "    \n",
    "    # normalization part\n",
    "    data_X, feat_mean, feat_std = normalization(data_X, mean = mean, variance = variance, norm_para=norm_para)\n",
    "#     print('data_X: {}'.format([x for x in data_X[7]]))\n",
    "    return data_X, data_Y, (feat_mean, feat_std)\n",
    "    \n",
    "\n",
    "def train(train_data, dev_data, it = 5, check_freq = 5000, smart_avg = False):\n",
    "    train_size = len(train_data)\n",
    "    dimension = len(train_data[0][0])\n",
    "    model = np.zeros(dimension)\n",
    "    totmodel = np.zeros(dimension)\n",
    "    c, smart_tot = 0, np.zeros(dimension)\n",
    "    best_err_rate = best_err_rate_avg = best_positive = best_positive_avg = 1\n",
    "    t = time.time()\n",
    "    for i in range(it):\n",
    "        updates = 0\n",
    "        for j, (vecx, y) in enumerate(train_data, start = 1):\n",
    "            c += 1\n",
    "            if model.dot(vecx) * y <= 0:\n",
    "                updates += 1\n",
    "                model += y * vecx\n",
    "                if smart_avg:\n",
    "                    smart_tot += c * y * vecx\n",
    "            if not smart_avg:\n",
    "                totmodel += model\n",
    "            if (j+i*train_size) % check_freq == 0:\n",
    "                dev_err_rate, positive = test_dev(dev_data, model)\n",
    "                dev_err_rate_avg, positive_avg = test_dev(dev_data,  model - smart_tot/c if smart_avg else totmodel)\n",
    "                epoch_position = i + j/train_size\n",
    "\n",
    "                if dev_err_rate < best_err_rate:        # update a better error\n",
    "                    best_err_rate = dev_err_rate\n",
    "                    best_err_pos = epoch_position #(i, j)\n",
    "                    best_positive = positive\n",
    "                if dev_err_rate_avg < best_err_rate_avg:\n",
    "                    best_err_rate_avg = dev_err_rate_avg\n",
    "                    best_err_pos_avg = epoch_position #(i, j)\n",
    "                    best_positive_avg = positive_avg\n",
    "                    best_avg_model = model - smart_tot/c if smart_avg else totmodel.copy() #copy() is important\n",
    "                print(\"unavg, epoch {} updates {} ({:.1%}) dev_err {:.1%} (+:{:.1%});   \".format(i+1,\n",
    "                                                            updates,\n",
    "                                                            updates/train_size,\n",
    "                                                            dev_err_rate,\n",
    "                                                            positive), \\\n",
    "                \"avg, epoch {} dev_err {:.1%} (+:{:.1%})\".format(i+1,\n",
    "                                                            dev_err_rate_avg,\n",
    "                                                            positive_avg))\n",
    "    print(\"training time {:.5f} s\".format(time.time()-t))\n",
    "    return best_avg_model/it/len(train_data)\n",
    "\n",
    "def test_dev(data, model):\n",
    "    errors = sum(model.dot(vecx) * y <= 0 for vecx, y in data)\n",
    "    positives = sum(model.dot(vecx) > 0 for vecx, _ in data)\n",
    "    return errors / len(data), positives / len(data)\n",
    "\n",
    "def predict(test_data, model):\n",
    "    return [\">50K\" if model.dot(vecx) > 0 else \"<=50K\" for vecx in test_data ]\n",
    "\n",
    "def create_feature_map(train_file):\n",
    "    column_values = defaultdict(set)\n",
    "    for line in open(train_file):\n",
    "        features = line.strip().split(\", \")[:-1] # last field is target.\n",
    "        for i, fv in enumerate(features):\n",
    "            # if i in numerical: continue    # uncommand to keep only binarized/numerical features for age and hours, command out to keep both\n",
    "            column_values[i].add(fv)\n",
    "    \n",
    "    feature2index = {(-1, 'bias'): 0} # bias\n",
    "    index2feature = {0: ('col-1', 'bias')}\n",
    "    \n",
    "    for i, values in column_values.items():\n",
    "        for v in values:\n",
    "            feature2index[i, v] = len(feature2index)\n",
    "            index2feature[len(feature2index) - 1] = ('col'+str(i),v)\n",
    "                        \n",
    "    # engineering for feature combination\n",
    "    for i, j in combinations(comb, 2):\n",
    "        for v1 in column_values[i]:\n",
    "            for v2 in  column_values[j]:\n",
    "                feature2index[i, v1, j, v2] = len(feature2index)\n",
    "                index2feature[len(feature2index) - 1] = ('col'+str(i),v1,'col'+str(j),v2)\n",
    "    dimension = len(feature2index) + len(numerical)\n",
    "    print(\"dimensionality: \", dimension)\n",
    "    return feature2index, index2feature\n",
    "\n",
    "\n",
    "def experiment(train_file, dev_file, test_file = '', it = 1, check_freq = 5000, feat_detail = False, mean = False, variance = False):\n",
    "    feature2index,index2feature = create_feature_map(train_file)\n",
    "#     print('feature2index: {}'.format(feature2index))\n",
    "#     print('index2feature: {}'.format(index2feature))\n",
    "    \n",
    "    X1, Y1, norm = map_data(train_file, feature2index, mean, variance)\n",
    "    train_data   = list(zip(X1, Y1))\n",
    "    \n",
    "    X2, Y2, _    = map_data(dev_file, feature2index, mean, variance, norm_para=norm)\n",
    "    dev_data     = list(zip(X2, Y2))\n",
    "    \n",
    "    model = train(train_data, dev_data, it, check_freq)\n",
    "\n",
    "    print(\"train_err {:.2%} (+:{:.1%})\".format(*test_dev(train_data, model)))\n",
    "\n",
    "    # display feature details (top 5 pos weights, top5 neg weights, etc)\n",
    "    if feat_detail: \n",
    "        print([(index2feature[i], '{:.5}'.format(model[i])) for i in model.argsort()[-5:][::-1]])\n",
    "        print([(index2feature[i], '{:.5}'.format(model[i])) for i in model.argsort()[:5]])\n",
    "        print([(i, model[feature2index[-1,i]]) for i in ['bias']])\n",
    "        print([(i, model[feature2index[6,i]]) for i in ['Male', 'Female']])\n",
    "\n",
    "    # predict blind test if test_file name is assigned\n",
    "    if test_file != '':\n",
    "        test_data_X, _, _  = map_data(test_file, feature2index, mean, variance, norm_para=norm)\n",
    "        labels = predict(test_data_X, model)\n",
    "        positive = sum([1 for x in labels if x == '>50K'])/len(labels)\n",
    "        fout = open(test_file+'_pred','w')\n",
    "        for j, line in enumerate(open(test_file)):\n",
    "            fout.write(line[:-1]+', '+labels[j]+'\\n')\n",
    "        fout.close()\n",
    "        print('(+:{:.1%}), prediction written to {}'.format(positive, test_file+'_pred'))\n",
    " \n",
    "def exp():\n",
    "    print(\"{}\\nPerceptron and Averaged Perceptron\".format('-'*N_dash))\n",
    "    experiment(train_file, dev_file,it=it,feat_detail=False,mean=mean_,variance=variance_)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#     if len(sys.argv) > 1:\n",
    "#         train_file, dev_file = sys.argv[1], sys.argv[2]\n",
    "#     else:\n",
    "    train_file, dev_file = \"income.train.txt.5k\", \"income.dev.txt\"\n",
    "    test_file = \"./hw1-data/income.test.blind\"\n",
    "\n",
    "    mean_ = True\n",
    "    variance_ = False\n",
    "    it = 5\n",
    "\n",
    "    N_dash = 40\n",
    "\n",
    "    # here are tunnung on numerical features and combinations\n",
    "    numerical = []#[0, 7]\n",
    "    # numerical = [0,7]\n",
    "    comb = []\n",
    "    # comb=[4,6]\n",
    "    comb = [4,5,8]\n",
    "    # comb = [0,5,6,7,8]\n",
    "    # comb = [0,1,2,3,4,5,6,7,8]\n",
    "    exp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
